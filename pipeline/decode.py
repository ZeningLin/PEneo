from typing import Dict, List, Tuple

import torch

from model.peneo_decoder import HandshakingTaggingScheme


def parse_matrix_spots(
    matrix_spots: List[Tuple], top_score_only: bool = False, triu_mode: bool = False
) -> Dict[int, int]:
    """Parse matrix spots to a dict.

    Parameters
    ----------
    matrix_spots : List[Tuple]
        A list of matrix spots decoded by HandshakingTaggingScheme.get_spots_from_shaking_tag
    top_score_only : bool, optional
        If True, only keep the spot with the highest score for each head index,
        by default False
    triu_mode : bool, optional
        If True, elements tagged as 2 are considered as the lower triangle of the matrix,
        by default False

    Returns
    -------
    Dict[int, int]
        A dict of spot mapping from head index to tail index

    """
    spot_map = {}
    for sp in matrix_spots:
        head_idx, tail_idx, tag, score = sp
        if tag == 0:
            continue
        if triu_mode and tag == 2:
            head_idx, tail_idx = tail_idx, head_idx

        if not top_score_only:
            if head_idx in spot_map.keys():
                spot_map[head_idx].append(tail_idx)
            else:
                spot_map[head_idx] = [tail_idx]
        else:
            if head_idx not in spot_map.keys():
                spot_map[head_idx] = (tail_idx, score)
            else:
                if score > spot_map[head_idx][1]:
                    spot_map[head_idx] = (tail_idx, score)

    if top_score_only:
        # each element has only one input and only one output
        reverse_map = {}
        for k, (v, s) in spot_map.items():
            if v not in reverse_map.keys():
                reverse_map[v] = (k, s)
            else:
                if s > reverse_map[v][1]:
                    reverse_map[v] = (k, s)

        spot_map = {k[0]: v for v, k in reverse_map.items()}

    return spot_map


def sample_decode_peneo(
    handshaking_tagger: HandshakingTaggingScheme,
    text: List[str],
    line_extraction_shaking: torch.Tensor,
    ent_linking_h2h_shaking: torch.Tensor,
    ent_linking_t2t_shaking: torch.Tensor,
    line_grouping_h2h_shaking: torch.Tensor,
    line_grouping_t2t_shaking: torch.Tensor,
    seq_len: int = None,
    shaking_ind2matrix_ind: List[Tuple[int]] = None,
    decode_gt: bool = False,
) -> Tuple:
    """Decode PEneo predictions/ground-truth tags of one sample,
    return the parsed kv-pairs, lines, and linkings

    Parameters
    ----------
    handshaking_tagger : HandshakingTaggingScheme
        A HandshakingTaggingScheme object defined in model/peneo_decoder.py,
        used for handshaking format conversion
    text : List[str]
        A list of text tokens used for content reconstruction. If you want
        to get the original text shown in your image, you should pass the
        fetched token list processed by the tokenizer fetcher
    line_extraction_shaking : torch.Tensor
        Prediction/ground-truth of line extraction
    ent_linking_h2h_shaking : torch.Tensor
        Prediction/ground-truth of entity linking (head-to-head)
    ent_linking_t2t_shaking : torch.Tensor
        Prediction/ground-truth of entity linking (tail-to-tail)
    line_grouping_h2h_shaking : torch.Tensor
        Prediction/ground-truth of line grouping (head-to-head)
    line_grouping_t2t_shaking : torch.Tensor
        Prediction/ground-truth of line grouping (tail-to-tail)
    seq_len : int, optional
        Sequence length used for handshaking index generation.
        If shaking_ind2matrix_ind is not given, this parameter is required,
        and a new index list will be generated by this parameter.
        If shaking_ind2matrix_ind is given, this parameter will be ignored.
        By default None
    shaking_ind2matrix_ind : List[Tuple[int]], optional
        Index map used to getting the row/column index from the
        handshaking results. If not given, it will be generated by seq_len.
        By default None
    decode_gt : bool, optional
        If True, decode ground-truth tags, otherwise decode PEneo predictions.
        By default False

    Returns
    -------
    parsed_kv_pairs : List[Tuple[str, str]]
        A list of key-value pairs parsed from the entity linking results
    parsed_lines : List[str]
        A list of lines parsed from the line extraction results
    line_extraction_memory_dict : Dict[int, int]
        A dict of line extraction mapping from head index to tail index
    entity_head_rel_memory_dict : Dict[int, int]
        A dict of entity linking mapping from head index to tail index
    entity_tail_rel_memory_dict : Dict[int, int]
        A dict of entity linking mapping from tail index to head index
    line_grouping_head_rel_memory_dict : Dict[int, int]
        A dict of line grouping mapping from head index to tail index
    line_grouping_tail_rel_memory_dict : Dict[int, int]
        A dict of line grouping mapping from tail index to head index
    """
    if shaking_ind2matrix_ind is None and seq_len is not None:
        shaking_ind2matrix_ind = [
            (ind, end_ind)
            for ind in range(seq_len)
            for end_ind in list(range(seq_len))[ind:]
        ]
    assert (
        shaking_ind2matrix_ind is not None
    ), f"seq_len or shaking_ind2matrix_ind must be given"
    line_extraction_matrix_spots = handshaking_tagger.get_spots_from_shaking_tag(
        shaking_tag=line_extraction_shaking,
        shaking_ind2matrix_ind=shaking_ind2matrix_ind,
    )
    ent_linking_h2h_matrix_spots = handshaking_tagger.get_spots_from_shaking_tag(
        shaking_tag=ent_linking_h2h_shaking,
        shaking_ind2matrix_ind=shaking_ind2matrix_ind,
    )
    ent_linking_t2t_matrix_spots = handshaking_tagger.get_spots_from_shaking_tag(
        shaking_tag=ent_linking_t2t_shaking,
        shaking_ind2matrix_ind=shaking_ind2matrix_ind,
    )
    line_grouping_h2h_matrix_spots = handshaking_tagger.get_spots_from_shaking_tag(
        shaking_tag=line_grouping_h2h_shaking,
        shaking_ind2matrix_ind=shaking_ind2matrix_ind,
    )
    line_grouping_t2t_matrix_spots = handshaking_tagger.get_spots_from_shaking_tag(
        shaking_tag=line_grouping_t2t_shaking,
        shaking_ind2matrix_ind=shaking_ind2matrix_ind,
    )

    # parse line-extraction results
    line_extraction_memory_dict = parse_matrix_spots(
        matrix_spots=line_extraction_matrix_spots,
        top_score_only=False if decode_gt else True,
        triu_mode=False,
    )

    # parse line-grouping results
    line_grouping_tail_rel_memory_dict = parse_matrix_spots(
        matrix_spots=line_grouping_t2t_matrix_spots,
        top_score_only=False if decode_gt else True,
        triu_mode=True,
    )
    line_grouping_head_rel_memory_dict = parse_matrix_spots(
        matrix_spots=line_grouping_h2h_matrix_spots,
        top_score_only=False if decode_gt else True,
        triu_mode=True,
    )

    if decode_gt:
        line_extraction_memory_dict = {
            k: v[0] for k, v in line_extraction_memory_dict.items()
        }
        line_grouping_tail_rel_memory_dict = {
            k: v[0] for k, v in line_grouping_tail_rel_memory_dict.items()
        }
        line_grouping_head_rel_memory_dict = {
            k: v[0] for k, v in line_grouping_head_rel_memory_dict.items()
        }

    parsed_lines = []
    for start_id, end_id in line_extraction_memory_dict.items():
        parsed_lines.append("".join(text[start_id : end_id + 1]))

    # parse entity-linking results,
    # then extract kv-pair
    parsed_kv_pairs = []
    entity_tail_rel_memory_dict = parse_matrix_spots(
        matrix_spots=ent_linking_t2t_matrix_spots, top_score_only=False, triu_mode=True
    )
    entity_head_rel_memory_dict = {}
    for sp in ent_linking_h2h_matrix_spots:
        key_head_idx, value_head_idx, tag, _ = sp
        if tag == 0:
            continue
        if tag == 2:
            key_head_idx, value_head_idx = value_head_idx, key_head_idx

        if key_head_idx in entity_head_rel_memory_dict.keys():
            entity_head_rel_memory_dict[key_head_idx].append(value_head_idx)
        else:
            entity_head_rel_memory_dict[key_head_idx] = [value_head_idx]

        key_first_line_tail_idx = line_extraction_memory_dict.get(key_head_idx, None)
        if key_first_line_tail_idx is None:
            continue
        value_first_line_tail_idx = line_extraction_memory_dict.get(
            value_head_idx, None
        )
        if value_first_line_tail_idx is None:
            continue

        key_first_line_text = "".join(text[key_head_idx : key_first_line_tail_idx + 1])
        key_text_list = [key_first_line_text]
        key_span_list = [(key_head_idx, key_first_line_tail_idx + 1)]
        key_curr_line_head_idx = key_head_idx
        key_curr_line_tail_idx = key_first_line_tail_idx
        key_next_line_head_idx = line_grouping_head_rel_memory_dict.get(
            key_curr_line_head_idx, None
        )
        while key_next_line_head_idx is not None:
            if key_next_line_head_idx == key_curr_line_head_idx:
                break

            le_key_next_line_tail_idx = line_extraction_memory_dict.get(
                key_next_line_head_idx, None
            )  # get next line tail idx from line extraction prediction
            if le_key_next_line_tail_idx is None:
                break
            lg_key_next_line_tail_idx = line_grouping_tail_rel_memory_dict.get(
                key_curr_line_tail_idx, None
            )  # get next line tail idx from line grouping prediction
            if lg_key_next_line_tail_idx != le_key_next_line_tail_idx:
                # if prediction from line extraction and line grouping are not matched, break
                break

            key_curr_line_text = "".join(
                text[key_next_line_head_idx : le_key_next_line_tail_idx + 1]
            )
            key_text_list.append(key_curr_line_text)
            key_span_list.append(
                (key_next_line_head_idx, le_key_next_line_tail_idx + 1)
            )

            key_curr_line_head_idx = key_next_line_head_idx
            key_curr_line_tail_idx = le_key_next_line_tail_idx
            key_next_line_head_idx = line_grouping_head_rel_memory_dict.get(
                key_curr_line_head_idx
            )

        value_first_line_text = "".join(
            text[value_head_idx : value_first_line_tail_idx + 1]
        )
        value_text_list = [value_first_line_text]
        value_span_list = [(value_head_idx, value_first_line_tail_idx + 1)]
        value_curr_line_head_idx = value_head_idx
        value_curr_line_tail_idx = value_first_line_tail_idx
        value_next_line_head_idx = line_grouping_head_rel_memory_dict.get(
            value_curr_line_head_idx, None
        )
        while value_next_line_head_idx is not None:
            if value_next_line_head_idx == value_curr_line_head_idx:
                break

            le_value_next_line_tail_idx = line_extraction_memory_dict.get(
                value_next_line_head_idx, None
            )
            if le_value_next_line_tail_idx is None:
                break
            lg_value_next_line_tail_idx = line_grouping_tail_rel_memory_dict.get(
                value_curr_line_tail_idx, None
            )
            if lg_value_next_line_tail_idx != le_value_next_line_tail_idx:
                break

            value_curr_line_text = "".join(
                text[value_next_line_head_idx : le_value_next_line_tail_idx + 1]
            )
            value_text_list.append(value_curr_line_text)
            value_span_list.append(
                (value_next_line_head_idx, le_value_next_line_tail_idx + 1)
            )

            value_curr_line_head_idx = value_next_line_head_idx
            value_curr_line_tail_idx = le_value_next_line_tail_idx
            value_next_line_head_idx = line_grouping_head_rel_memory_dict.get(
                value_curr_line_head_idx
            )

        # check validation of key-value pair
        valid_value_tails = entity_tail_rel_memory_dict.get(
            key_curr_line_tail_idx, None
        )
        if (
            valid_value_tails is not None
            and value_curr_line_tail_idx in valid_value_tails
        ):
            key_text = "".join(key_text_list).strip()
            value_text = "".join(value_text_list).strip()

            parsed_kv_pairs.append((key_text, value_text))

    return (
        parsed_kv_pairs,
        parsed_lines,
        line_extraction_memory_dict,
        entity_head_rel_memory_dict,
        entity_tail_rel_memory_dict,
        line_grouping_head_rel_memory_dict,
        line_grouping_tail_rel_memory_dict,
    )


def decode_peneo(
    handshaking_tagger: HandshakingTaggingScheme,
    texts: List[List[str]],
    line_extraction_shaking_outputs: torch.Tensor,
    ent_linking_h2h_shaking_outputs: torch.Tensor,
    ent_linking_t2t_shaking_outputs: torch.Tensor,
    line_grouping_h2h_shaking_outputs: torch.Tensor,
    line_grouping_t2t_shaking_outputs: torch.Tensor,
    line_extraction_shaking_tags: torch.Tensor,
    ent_linking_h2h_shaking_tags: torch.Tensor,
    ent_linking_t2t_shaking_tags: torch.Tensor,
    line_grouping_h2h_shaking_tags: torch.Tensor,
    line_grouping_t2t_shaking_tags: torch.Tensor,
    orig_bboxes: List[List[Tuple[int]]],
    file_ids: List[str],
):
    """Decode predictions and ground-truth tags

    Parameters
    ----------
    handshaking_tagger : HandshakingTaggingScheme
        A HandshakingTaggingScheme object defined in model/peneo_decoder.py,
    texts : List[List[str]]
        A list of text tokens used for content reconstruction. If you want
        to get the original text shown in your image, you should pass the
        fetched token list processed by the tokenizer fetcher.
    line_extraction_shaking_outputs : torch.Tensor
        Prediction of line extraction
    ent_linking_h2h_shaking_outputs : torch.Tensor
        Prediction of entity linking (head-to-head)
    ent_linking_t2t_shaking_outputs : torch.Tensor
        Prediction of entity linking (tail-to-tail)
    line_grouping_h2h_shaking_outputs : torch.Tensor
        Prediction of line grouping (head-to-head)
    line_grouping_t2t_shaking_outputs : torch.Tensor
        Prediction of line grouping (tail-to-tail)
    line_extraction_shaking_tags : torch.Tensor
        Ground-truth of line extraction
    ent_linking_h2h_shaking_tags : torch.Tensor
        Ground-truth of entity linking (head-to-head)
    ent_linking_t2t_shaking_tags : torch.Tensor
        Ground-truth of entity linking (tail-to-tail)
    line_grouping_h2h_shaking_tags : torch.Tensor
        Ground-truth of line grouping (head-to-head)
    line_grouping_t2t_shaking_tags : torch.Tensor
        Ground-truth of line grouping (tail-to-tail)
    orig_bboxes : List[List[Tuple[int]]]
        A list of bounding boxes of the tokens,
        mainly used for getting the sequence length
        and generating the index map
    file_ids : List[str]
        A list of file ids used for identifying the samples

    Returns
    -------
    The parsed predictions, ground-truth tags,
    and file ids of the non-empty samples
    """
    all_pred_results, all_gt_results, all_file_ids = [], [], []
    for idx, (
        line_extraction_shaking_output,
        ent_linking_h2h_shaking_output,
        ent_linking_t2t_shaking_output,
        line_grouping_h2h_shaking_output,
        line_grouping_t2t_shaking_output,
        line_extraction_shaking_tag,
        ent_linking_h2h_shaking_tag,
        ent_linking_t2t_shaking_tag,
        line_grouping_h2h_shaking_tag,
        line_grouping_t2t_shaking_tag,
        text,
        orig_bbox,
        file_id,
    ) in enumerate(
        zip(
            line_extraction_shaking_outputs,
            ent_linking_h2h_shaking_outputs,
            ent_linking_t2t_shaking_outputs,
            line_grouping_h2h_shaking_outputs,
            line_grouping_t2t_shaking_outputs,
            line_extraction_shaking_tags,
            ent_linking_h2h_shaking_tags,
            ent_linking_t2t_shaking_tags,
            line_grouping_h2h_shaking_tags,
            line_grouping_t2t_shaking_tags,
            texts,
            orig_bboxes,
            file_ids,
        )
    ):
        if len(texts) == 0:
            # skip empty samples
            continue

        seq_len = len(orig_bbox)
        shaking_ind2matrix_ind = [
            (ind, end_ind)
            for ind in range(seq_len)
            for end_ind in list(range(seq_len))[ind:]
        ]

        all_pred_results.append(
            sample_decode_peneo(
                handshaking_tagger=handshaking_tagger,
                text=text,
                line_extraction_shaking=line_extraction_shaking_output,
                ent_linking_h2h_shaking=ent_linking_h2h_shaking_output,
                ent_linking_t2t_shaking=ent_linking_t2t_shaking_output,
                line_grouping_h2h_shaking=line_grouping_h2h_shaking_output,
                line_grouping_t2t_shaking=line_grouping_t2t_shaking_output,
                shaking_ind2matrix_ind=shaking_ind2matrix_ind,
                decode_gt=False,
            )
        )

        all_gt_results.append(
            sample_decode_peneo(
                handshaking_tagger=handshaking_tagger,
                text=text,
                line_extraction_shaking=line_extraction_shaking_tag,
                ent_linking_h2h_shaking=ent_linking_h2h_shaking_tag,
                ent_linking_t2t_shaking=ent_linking_t2t_shaking_tag,
                line_grouping_h2h_shaking=line_grouping_h2h_shaking_tag,
                line_grouping_t2t_shaking=line_grouping_t2t_shaking_tag,
                shaking_ind2matrix_ind=shaking_ind2matrix_ind,
                decode_gt=True,
            )
        )
        all_file_ids.append(file_id)

    return all_pred_results, all_gt_results, all_file_ids
